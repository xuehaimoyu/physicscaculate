{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34d0e0fa",
   "metadata": {},
   "source": [
    "# 调用必备库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fc0cb58d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x1a7d9bf8110>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "from torch.autograd import Variable\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20df8a3c",
   "metadata": {},
   "source": [
    "# 先随便搭建个简单的神经网络\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f9e9172",
   "metadata": {},
   "source": [
    "尝试求解一下两端点固定的自由振动问题\n",
    "\n",
    "$u_{tt}-a^2u_{xx}=0$\n",
    "\n",
    "$u(0,x)=sinx$\n",
    "\n",
    "$u_t(0,x)=cosx$\n",
    "\n",
    "$u(t,0)=0,u(l,t)=0$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "207bea1c",
   "metadata": {},
   "source": [
    "## 神经网络求解"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c7f2da68",
   "metadata": {},
   "outputs": [],
   "source": [
    "class zsrDGM_net(nn.Module):\n",
    "    def __init__(self,numl,numn):\n",
    "        # numl是有多少层隐藏层\n",
    "        # numn是每层的神经元数量\n",
    "        super(zsrDGM_net, self).__init__()\n",
    "        self.input_layer = nn.Linear(2, numn)#前面的数字代表几个输入\n",
    "        self.hidden_layers = nn.ModuleList([nn.Linear(numn, numn) for i in range(numl)])\n",
    "        self.output_layer = nn.Linear(numn, 1)\n",
    "    def forward(self, x):\n",
    "        o = self.act(self.input_layer(x))\n",
    "        for i, li in enumerate(self.hidden_layers):\n",
    "            o = self.act(li(o))        \n",
    "        out = self.output_layer(o)        \n",
    "        return out\n",
    "    def act(self, x):\n",
    "        return x * torch.tanh(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "130e88b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDE():\n",
    "    def __init__(self, net, a,l,t):\n",
    "        self.net=net\n",
    "        self.a=a\n",
    "        self.l=l\n",
    "        self.t=t\n",
    "    def sample(self,size=2**8):        \n",
    "        x = torch.cat((torch.rand([size, 1]) * self.t, torch.rand([size, 1]) * self.l), dim=1)\n",
    "        x_init = torch.rand([size, 1]) * self.l\n",
    "        x_initial = torch.cat((torch.zeros(size, 1), x_init), dim=1)\n",
    "        x_boundary_left = torch.cat((torch.rand([size, 1])*self.t, torch.full([size, 1], 0)), dim=1)\n",
    "        x_boundary_right = torch.cat((torch.rand([size, 1])*self.t, torch.full([size, 1], l)), dim=1)\n",
    "        return x, x_initial, x_init, x_boundary_left, x_boundary_right\n",
    "    def loss_func(self,size=2**8):\n",
    "        x_train, x_initial, x_init, x_boundary_left, x_boundary_right = self.sample(size=size)\n",
    "        x = Variable(x_train, requires_grad=True)\n",
    "        d = torch.autograd.grad(net(x), x, grad_outputs=torch.ones_like(net(x)), create_graph=True)\n",
    "        dt = d[0][:, 0].unsqueeze(-1)\n",
    "        dx = d[0][:, 1].unsqueeze(-1)\n",
    "        dxx = torch.autograd.grad(dx, x, grad_outputs=torch.ones_like(dx), create_graph=True)[0][:, 1].unsqueeze(-1)\n",
    "        dtt = torch.autograd.grad(dt, x, grad_outputs=torch.ones_like(dt), create_graph=True)[0][:, 1].unsqueeze(-1)\n",
    "        x2=Variable(x_initial, requires_grad=True)\n",
    "        d1 = torch.autograd.grad(net(x2), x2, grad_outputs=torch.ones_like(net(x2)), create_graph=True)\n",
    "        dt1 = d1[0][:, 0].unsqueeze(-1)\n",
    "        loss_fn = nn.MSELoss(reduction='mean')\n",
    "        loss1 = loss_fn(dtt, self.a**2*dxx)\n",
    "        loss2 = loss_fn(net(x_initial), torch.sin(x_init))\n",
    "        loss3 = loss_fn(net(x_boundary_left), torch.zeros([size, 1]))\n",
    "        loss4 = loss_fn(net(x_boundary_right), torch.zeros([size, 1]))\n",
    "        loss5 = loss_fn(dt1,1*torch.cos(x_init))\n",
    "        loss = loss1 + loss2 + loss3 + loss4+ loss5\n",
    "        return loss,loss1,loss2,loss3,loss4,loss5\n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b745b839",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Train():\n",
    "    def __init__(self, net, eq, BATCH_SIZE):\n",
    "        self.errors = []\n",
    "        self.BATCH_SIZE = BATCH_SIZE\n",
    "        self.net = net\n",
    "        self.model = eq\n",
    "    def train(self, epoch, lr):\n",
    "        optimizer = optim.Adam(self.net.parameters(), lr)\n",
    "        avg_loss = 0\n",
    "        for e in range(epoch):\n",
    "            optimizer.zero_grad()\n",
    "            loss,loss1,loss2,loss3,loss4,loss5 = self.model.loss_func(self.BATCH_SIZE)\n",
    "            avg_loss = avg_loss + float(loss.item())\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            if e % 50 == 49:\n",
    "                loss = avg_loss/50\n",
    "                print(\"Epoch {} - lr {} -  loss: {}\".format(e, lr, loss))\n",
    "                avg_loss = 0\n",
    "\n",
    "                error,loss1,loss2,loss3,loss4,loss5 = self.model.loss_func(2**12)\n",
    "                self.errors.append(error.detach())\n",
    "    def get_errors(self):\n",
    "        return self.errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b20d721a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49 - lr 0.0001 -  loss: 1.0489021706581116\n",
      "Epoch 99 - lr 0.0001 -  loss: 0.9181552374362946\n",
      "Epoch 149 - lr 0.0001 -  loss: 0.7375347304344178\n",
      "Epoch 199 - lr 0.0001 -  loss: 0.6750632786750793\n",
      "Epoch 249 - lr 0.0001 -  loss: 0.49285370349884033\n",
      "Epoch 299 - lr 0.0001 -  loss: 0.21372802823781967\n",
      "Epoch 349 - lr 0.0001 -  loss: 0.13732985004782677\n",
      "Epoch 399 - lr 0.0001 -  loss: 0.10072590097784996\n",
      "Epoch 449 - lr 0.0001 -  loss: 0.06477287232875824\n",
      "Epoch 499 - lr 0.0001 -  loss: 0.053275579288601875\n",
      "Epoch 549 - lr 0.0001 -  loss: 0.0359943887591362\n",
      "Epoch 599 - lr 0.0001 -  loss: 0.03590043190866709\n",
      "Epoch 649 - lr 0.0001 -  loss: 0.021922803670167922\n",
      "Epoch 699 - lr 0.0001 -  loss: 0.02135512441396713\n",
      "Epoch 749 - lr 0.0001 -  loss: 0.016542741991579533\n",
      "Epoch 799 - lr 0.0001 -  loss: 0.015779891069978475\n",
      "Epoch 849 - lr 0.0001 -  loss: 0.015574104096740484\n",
      "Epoch 899 - lr 0.0001 -  loss: 0.012272395845502614\n",
      "Epoch 949 - lr 0.0001 -  loss: 0.012772510964423419\n",
      "Epoch 999 - lr 0.0001 -  loss: 0.011864930540323258\n",
      "Epoch 1049 - lr 0.0001 -  loss: 0.009312702668830752\n",
      "Epoch 1099 - lr 0.0001 -  loss: 0.011807137038558721\n",
      "Epoch 1149 - lr 0.0001 -  loss: 0.00932796036824584\n",
      "Epoch 1199 - lr 0.0001 -  loss: 0.00965738844126463\n",
      "Epoch 1249 - lr 0.0001 -  loss: 0.008282348532229662\n",
      "Epoch 1299 - lr 0.0001 -  loss: 0.008507451443001628\n",
      "Epoch 1349 - lr 0.0001 -  loss: 0.007225914588198066\n",
      "Epoch 1399 - lr 0.0001 -  loss: 0.008589357016608118\n",
      "Epoch 1449 - lr 0.0001 -  loss: 0.0074326901976019145\n",
      "Epoch 1499 - lr 0.0001 -  loss: 0.005756524614989758\n"
     ]
    }
   ],
   "source": [
    "net = zsrDGM_net(numl=7, numn=300)\n",
    "a=1\n",
    "l=np.pi\n",
    "t=1\n",
    "equation = PDE(net, a, l,t)\n",
    "train = Train(net, equation, BATCH_SIZE=2**8)\n",
    "train.train(epoch=1500, lr=0.0001)\n",
    "torch.save(net, 'test.pkl')\n",
    "errors = train.get_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "df8ecd01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\cm\\anaconda3\\envs\\pytorch\\lib\\site-packages\\matplotlib\\animation.py:879: UserWarning: Animation was deleted without rendering anything. This is most likely not intended. To prevent deletion, assign the Animation to a variable, e.g. `anim`, that exists until you output the Animation using `plt.show()` or `anim.save()`.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "plt.plot(np.log(errors), '-b', label='Errors')\n",
    "plt.title('Training Loss', fontsize=10)\n",
    "plt.savefig('error.jpg')\n",
    "plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ce30ffe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import PyQt5\n",
    "%matplotlib qt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cea7a899",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import animation\n",
    "import numpy as np\n",
    "net=torch.load('test.pkl')\n",
    "fig, ax = plt.subplots()\n",
    "err=[]\n",
    "# 定义存储数据的列表\n",
    "xdata = []\n",
    "ydata = []\n",
    "\n",
    "# 接收line2D对象\n",
    "line, = plt.plot(xdata, ydata, 'b')\n",
    "xdata=[i/100 for i in range(0,314)]\n",
    "# 定义更新函数\n",
    "def update(frames):\n",
    "    x_1 = torch.tensor([[i/100] for i in range(0,314)])\n",
    "    x_11 = torch.cat((torch.full([314, 1],frames), x_1), dim=1)\n",
    "    ysolve1=net(x_11)\n",
    "    ysolve=ysolve1.detach().numpy()\n",
    "    ydata=[ysolve]\n",
    "    line.set_data(xdata, ydata)\n",
    "    return line\n",
    "\n",
    "\n",
    "def init_figure():\n",
    "    ax.set_xlim(0, 3.14)\n",
    "    ax.set_ylim(-2,2)\n",
    "    ax.set_xlabel('x')\n",
    "    ax.set_ylabel('u')\n",
    "\n",
    "\n",
    "# 调用生成动画的函数生成动图\n",
    "ani = animation.FuncAnimation(\n",
    "    fig=fig,\n",
    "    func=update,\n",
    "    frames=np.linspace(0, 1, 100),    # [1, 2, 3]\n",
    "    init_func=init_figure,\n",
    "    interval=20,   #  每隔多少时间生成一帧图像，单位是ms\n",
    "    repeat=True,   # 设置不重复，但是还是重复较好\n",
    ")\n",
    "\n",
    "#plt.show()   # 如果要保存视频和gif就不要show()\n",
    "#ani.save('shuli.gif', writer='pillow')\n",
    "ani.save('1.mp4', writer='ffmpeg')  # 注意，pillow现在似乎不能报错为mp4格式了，可以使用ffmpeg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "422558df",
   "metadata": {},
   "source": [
    "# 神经网络的搭建\n",
    "论文作者的建立结构"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58847fb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DGM_layer(nn.Module):#中间层的建立\n",
    "    \n",
    "    def __init__(self, in_features, out_feature, residual = False):\n",
    "        super(DGM_layer, self).__init__()\n",
    "        self.residual = residual\n",
    "        \n",
    "        self.Z = nn.Linear(out_feature,out_feature) ; self.UZ = nn.Linear(in_features,out_feature, bias=False)\n",
    "        self.G = nn.Linear(out_feature,out_feature) ; self.UG = nn.Linear(in_features,out_feature, bias=False)\n",
    "        self.R = nn.Linear(out_feature,out_feature) ; self.UR = nn.Linear(in_features,out_feature, bias=False)\n",
    "        self.H = nn.Linear(out_feature,out_feature) ; self.UH = nn.Linear(in_features,out_feature, bias=False)\n",
    "    \n",
    "\n",
    "    def forward(self, x, s):#激活函数\n",
    "        z = torch.tanh(self.UZ(x)+self.Z(s))\n",
    "        g = torch.tanh(self.UG(x)+self.G(s))\n",
    "        r = torch.tanh(self.UR(x)+self.R(s))\n",
    "        h = torch.tanh(self.UH(x)+self.H(s*r))\n",
    "        return (1 - g) * h + z*s\n",
    "\n",
    "class DGM_net(nn.Module):\n",
    "    def __init__(self, in_dim,out_dim, n_layers, n_neurons, residual = False):\n",
    "        \"\"\" in_dim is number of cordinates + 1 \n",
    "            out_dim is the number of output\n",
    "            n_layers and n_neurons are pretty self explanatory\n",
    "            make residual = true for identity between each DGM layers\n",
    "        \"\"\"\n",
    "        super(DGM_net, self).__init__()\n",
    "        self.in_dim = in_dim ; self.out_dim = out_dim\n",
    "        self.n_layers = n_layers\n",
    "        self.n_neurons = n_neurons\n",
    "        self.residual = residual\n",
    "\n",
    "        self.first_layer = nn.Linear(in_dim, n_neurons)#输入层\n",
    "        \n",
    "        self.dgm_layers = nn.ModuleList([DGM_layer(self.in_dim, self.n_neurons,\n",
    "                                                       self.residual) for i in range(self.n_layers)])#构建hidden layers\n",
    "        self.final_layer = nn.Linear(n_neurons,out_dim)#输出层\n",
    "    \n",
    "    def forward(self,x):\n",
    "        s = torch.relu(self.first_layer(x))\n",
    "        for i,dgm_layer in enumerate(self.dgm_layers):\n",
    "            s = dgm_layer(x, s)\n",
    "        \n",
    "        return  self.final_layer(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2f75c9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "net = DGM_net(2,1,3,30)\n",
    "a=1\n",
    "l=3\n",
    "t=3\n",
    "equation = PDE(net, a, l,t)\n",
    "train = Train(net, equation, BATCH_SIZE=2**8)\n",
    "train.train(epoch=3000, lr=0.0001)\n",
    "torch.save(net, 'test.pkl')\n",
    "errors = train.get_errors()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e87096f",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_1 = torch.tensor([[i/10] for i in range(0,10)])\n",
    "x_11 = torch.cat((torch.full([10, 1],0.3), x_1), dim=1)\n",
    "ysolve=net(x_11)\n",
    "print(ysolve)\n",
    "ysolve=ysolve.detach().numpy()\n",
    "x_range=[i/10 for i in range(0,10)]\n",
    "fig=plt.figure(dpi=60)\n",
    "plt.plot(x_range,u_true)\n",
    "plt.plot(x_range,(ysolve))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec6d035",
   "metadata": {},
   "source": [
    "ps：在网上查找过程中也找到了不一样的网络结构，不一定非用作者提供的这一个"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3c79e71",
   "metadata": {},
   "source": [
    "## burgers equation\n",
    "伯格斯方程(Burgers equation) 是一个模拟冲击波的传播和反射的非线性偏微分方程。\n",
    "\n",
    "在一系列问题设置（例如，不同的物理条件和边界条件）上找到PDE的解通常是很有意义的。\n",
    "\n",
    "传统的方法是离散P-空间，并对许多不同的点P多次重新求解PDE。\n",
    "\n",
    "然而，网格点的总数（因此，必须求解的PDE的数量）随着维数的增加呈指数增长，Pis通常是高维的。 对于不同的边界条件、初始条件和物理条件，我们建议使用DGM算法将一般解近似为PDE。使用随机梯度下降在随机时间、空间和问题设置点（t、x、p）序列上训练深度神经网络。\n",
    "\n",
    "如果x低维（d≤3） 这在许多物理偏微分方程中是常见的，f的一阶和二阶偏导数可以通过链式规则计算或用有限差分近似。我们在有限域上实现了Burgers方程的算法。\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94739a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "a=0.1\n",
    "T = (2 * np.pi / a) * np.array([0.00000000000000000001, 0])  # GAMA点由于计算误差，需要加一个小的正实数\n",
    "M = (2 * np.pi / a) * np.array([1 / 2, 1 / 2])  # 高对称点的坐标\n",
    "X = (2 * np.pi / a) * np.array([1 / 2, 0])\n",
    "z=0.3 * (X - T) + T\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e32b81f",
   "metadata": {},
   "outputs": [],
   "source": [
    "G=np.array([[1,2,3,4],[5,6,7,8],[9,10,11,12],[13,14,15,16]])\n",
    "print(G)\n",
    "for i in range(0,3):\n",
    "    for j in range(i+1,4):\n",
    "        print(G[i,:])\n",
    "        print('*')\n",
    "        print(G[j,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b1e26c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
